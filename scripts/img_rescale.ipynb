{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation des modules nécessaires au redimensionnement\n",
    "\n",
    "Code adapté à partir du script de création de *dataset* proposé par l'équipe de Silknow et disponible sur leur [GitHub]( https://github.com/silknow/image-classification/blob/master/silknow_image_classification/src/DatasetCreation.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérification du chemin d'accès et des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lise/memoire/scripts'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lise/memoire\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/lise/memoire/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redimensionnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescaleImages(directory):\n",
    "    imgpath_load = directory + r\"/img_unscaled/\"\n",
    "    imgpath_save = directory + r\"/img_rescaled/\"\n",
    "    if not os.path.exists(imgpath_save):\n",
    "        os.makedirs(imgpath_save)\n",
    "\n",
    "    imglist = os.listdir(imgpath_load)\n",
    "    print(\"\\nTotal number of images: \", len(imglist))\n",
    "\n",
    "    # for img_file in tqdm(imglist):\n",
    "    deadlist_load = []\n",
    "    deadlist_scale = []\n",
    "    print(\"\\nIterating over images (download): \")\n",
    "    for img_file in tqdm(imglist, total=len(imglist)):\n",
    "\n",
    "        # Skip images that are already scaled\n",
    "        if os.path.exists(imgpath_save + img_file): continue\n",
    "\n",
    "        # Try to open images, skip else\n",
    "        try:\n",
    "            img = plt.imread(imgpath_load + img_file)\n",
    "        except:\n",
    "            deadlist_load += [img_file]\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # get dimensions of image\n",
    "            if len(img.shape) == 2:\n",
    "                width, heigth = img.shape\n",
    "                img_new = np.zeros([img.shape[0], img.shape[1], 3], dtype=np.uint8)\n",
    "                img_new[:, :, 0], img_new[:, :, 1], img_new[:, :, 2] = img, img, img\n",
    "                img = img_new\n",
    "            elif len(img.shape) == 3:\n",
    "                width, heigth, _ = img.shape\n",
    "\n",
    "            smaller_side = np.minimum(heigth, width)\n",
    "            scale_factor = 448. / smaller_side\n",
    "\n",
    "                # If Downscaling, apply gaussian blur\n",
    "            if scale_factor < 1.:\n",
    "                sigma = 1. / scale_factor\n",
    "                kernelsize = int(sigma * 6) + (1 - (int(sigma * 6) % 2))\n",
    "                img = cv2.GaussianBlur(img, (kernelsize, kernelsize), sigma)\n",
    "\n",
    "            img_new = cv2.resize(img, (int(heigth * scale_factor), int(width * scale_factor)),\n",
    "                                     interpolation=cv2.INTER_CUBIC)\n",
    "            plt.imsave(imgpath_save + img_file, img_new)\n",
    "        except:\n",
    "            print(\"Erreur de mise à l'échelle:\"+img_file)\n",
    "            deadlist_scale += [img_file]\n",
    "\n",
    "    if len(deadlist_load) > 0:\n",
    "        print(\"\\nThe following images could not be opened: \")\n",
    "        for deadload in deadlist_load:\n",
    "            print(deadload)\n",
    "    if len(deadlist_scale) > 0:\n",
    "        print(\"\\nThe following images could not be scaled: \")\n",
    "        for _ in deadlist_scale:\n",
    "            print(deadlist_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of images:  273\n",
      "\n",
      "Iterating over images (download): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [00:23<00:00, 11.70it/s]\n"
     ]
    }
   ],
   "source": [
    "rescaleImages(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noms_images_txt(repertoire, nom_document):\n",
    "    contenu = \"\"\n",
    "\n",
    "    if not os.path.isdir(repertoire):\n",
    "        print(\"Le répertoire spécifié n'existe pas.\")\n",
    "        return\n",
    "\n",
    "    fichiers = sorted(os.listdir(repertoire))\n",
    "    for fichier in fichiers:\n",
    "        chemin_fichier = os.path.join(repertoire, fichier)\n",
    "        if os.path.isfile(chemin_fichier):\n",
    "            contenu += f\"{fichier}\\n\"\n",
    "\n",
    "    try:\n",
    "        with open(nom_document, \"w\") as fichier_txt:\n",
    "            fichier_txt.write(contenu)\n",
    "        print(f\"Le document '{nom_document}' a été créé avec succès.\")\n",
    "    except IOError:\n",
    "        print(\"Une erreur s'est produite lors de l'écriture du document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le document 'noms_images.txt' a été créé avec succès.\n"
     ]
    }
   ],
   "source": [
    "noms_images_txt(\"../images/img_rescaled/\", \"noms_images.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
